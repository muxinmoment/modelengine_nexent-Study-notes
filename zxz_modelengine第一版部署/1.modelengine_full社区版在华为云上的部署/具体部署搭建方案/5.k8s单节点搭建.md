# Kubernetes 单节点集群安装指南
# 以下是华为云上部署适配cri-docker的单节点k8s的具体实施步骤（贼复杂，做好心理准备）：

1. 环境准备
```bash
# 关闭防火墙
sudo systemctl disable ufw

# 控制台输出示例：
Synchronizing state of ufw.service with SysV service script with /usr/lib/systemd/systemd-sysv-install.
Executing: /usr/lib/systemd/systemd-sysv-install disable ufw
Removed "/etc/systemd/system/multi-user.target.wants/ufw.service".

# 禁用 swap
sudo swapoff -a
sudo sed -i '/swap/d' /etc/fstab

# 查看 fstab 确认 swap 已删除
cat /etc/fstab
# /etc/fstab: static file system information.
# ...
# / was on /dev/sda2 during curtin installation
# /dev/disk/by-uuid/6f925eb0-0250-407a-9582-abc16c003c43 / ext4 defaults 0 1
# /boot/efi was on /dev/sda1 during curtin installation
# /dev/disk/by-uuid/7918-87CD /boot/efi vfat defaults 0 1

# 确认 swap 已禁用
free -h
#               total        used        free      shared  buff/cache   available
# Mem:           7.6Gi       1.2Gi       1.8Gi       3.1Mi       4.8Gi       6.3Gi
# Swap:             0B          0B          0B

 2. 内核参数配置
# 创建内核参数文件
sudo tee /etc/sysctl.d/k8s.conf <<EOF
net.bridge.bridge-nf-call-ip6tables = 1
net.bridge.bridge-nf-call-iptables = 1
net.ipv4.ip_forward = 1
vm.swappiness = 0
EOF

# 加载内核模块
sudo modprobe br_netfilter

# 应用配置
sudo sysctl --system

# 控制台输出示例：
* Applying /etc/sysctl.d/k8s.conf ...
net.bridge.bridge-nf-call-ip6tables = 1
net.bridge.bridge-nf-call-iptables = 1
net.ipv4.ip_forward = 1
vm.swappiness = 0
* Applying /etc/sysctl.conf ...

 3. 安装依赖工具

sudo apt update
sudo apt install -y apt-transport-https ca-certificates curl

# 控制台输出示例：
Reading package lists... Done
Building dependency tree... Done
Reading state information... Done
ca-certificates is already the newest version (20240203).
The following additional packages will be installed:
  apt apt-utils libapt-pkg6.0t64
The following NEW packages will be installed:
  apt-transport-https
3 upgraded, 1 newly installed, 0 to remove and 188 not upgraded.
Need to get 2,580 kB of archives.
Setting up apt (2.8.3) ...
Setting up apt-transport-https (2.8.3) ...

4. 安装 Kubernetes 组件
# 添加 Kubernetes 阿里云源
sudo tee /etc/apt/sources.list.d/kubernetes.list <<EOF
deb https://mirrors.aliyun.com/kubernetes/apt/ kubernetes-xenial main
EOF

# 添加 GPG 密钥
curl -s https://mirrors.aliyun.com/kubernetes/apt/doc/apt-key.gpg | sudo gpg --dearmor -o /etc/apt/trusted.gpg.d/kubernetes-aliyun.gpg

# 更新源
sudo apt update

# 控制台输出示例：
Hit:1 https://mirrors.tuna.tsinghua.edu.cn/ubuntu noble InRelease
Get:5 https://mirrors.aliyun.com/kubernetes/apt kubernetes-xenial InRelease [8,993 B]
Fetched 78.9 kB in 6s (14.2 kB/s) 

# 安装 kubelet/kubeadm/kubectl
sudo apt install -y kubelet kubeadm kubectl

# 控制台输出示例：
The following additional packages will be installed:
  conntrack cri-tools ebtables kubernetes-cni socat
The following NEW packages will be installed:
  conntrack cri-tools ebtables kubeadm kubectl kubelet kubernetes-cni socat
Setting up conntrack (1:1.4.8-1ubuntu1) ...
Setting up kubectl (1.28.2-00) ...
Setting up kubelet (1.28.2-00) ...
Created symlink /etc/systemd/system/multi-user.target.wants/kubelet.service → /usr/lib/systemd/system/kubelet.service.

# 锁定版本防止自动升级
sudo apt-mark hold kubelet kubeadm kubectl
# kubelet set on hold.
# kubeadm set on hold.
# kubectl set on hold.

5. 初始化控制平面
# 选择cri-docker作为容器运行时
sudo kubeadm init \
  --image-repository registry.aliyuncs.com/google_containers \
  --cri-socket unix:///var/run/cri-dockerd.sock

# 控制台输出示例：
I0727 03:23:39.887454    4649 version.go:256] remote version is much newer: v1.33.3; falling back to: stable-1.28
[init] Using Kubernetes version: v1.28.15
[preflight] Running pre-flight checks
...
Your Kubernetes control-plane has initialized successfully!

To start using your cluster, you need to run the following as a regular user:
  mkdir -p $HOME/.kube
  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
  sudo chown $(id -u):$(id -g) $HOME/.kube/config

Alternatively, if you are the root user, you can run:
  export KUBECONFIG=/etc/kubernetes/admin.conf

# 配置 kubectl
export KUBECONFIG=/etc/kubernetes/admin.conf

# 检查节点状态
kubectl get nodes
# NAME           STATUS     ROLES           AGE   VERSION
# yu-ubuntu-vm   NotReady   control-plane   83s   v1.28.2

6.安装 Calico 网络插件
kubectl apply -f https://docs.projectcalico.org/manifests/calico.yaml

# 控制台输出示例：
poddisruptionbudget.policy/calico-kube-controllers created
serviceaccount/calico-kube-controllers created
...
daemonset.apps/calico-node created
deployment.apps/calico-kube-controllers created

# 等待 Pod 变为 Running
kubectl get pods -n kube-system -w
# calico-node-djnm7                          1/1     Running   0          5m

7. 移除节点污点（单节点专用）
# 检查当前污点
kubectl describe node | grep Taints
# Taints:             node-role.kubernetes.io/control-plane:NoSchedule

# 移除污点
kubectl taint nodes --all node-role.kubernetes.io/control-plane:NoSchedule-
# node/yu-ubuntu-vm untainted

# 确认污点已移除
kubectl describe node | grep Taints
# Taints:             <none>

8. 安装 Kubernetes Dashboard
# 安装 Helm
helm官网
https://github.com/helm/helm/releases/latest

#下载helm（适配arm64架构）
sudo wget https://get.helm.sh/helm-v3.18.4-linux-arm64.tar.gz

# 解压并安装（适配 ARM64 目录）
# 解压压缩包（解压后生成 linux-arm64 目录，而非 amd64）
sudo tar zxvf helm-v3.18.4-linux-arm64.tar.gz

# 查看解压结果（确认有 helm 二进制文件）
ls -lh linux-arm64/helm

# 移动 helm 到系统全局目录（所有用户可调用）
sudo mv linux-arm64/helm /usr/local/bin/

# 赋予执行权限（双重保险，避免权限问题）
sudo chmod 755 /usr/local/bin/helm

# 查看 Helm 版本（输出 v3.18.4 且无报错，即为成功）
helm version

# 添加 Dashboard 仓库
helm repo add kubernetes-dashboard https://kubernetes.github.io/dashboard/
# 更新仓库缓存（确保拉取最新 Chart）
helm repo update

#安装 Dashboard（创建独立命名空间）
helm upgrade --install kubernetes-dashboard kubernetes-dashboard/kubernetes-dashboard \
  --create-namespace \
  --namespace kubernetes-dashboard \
  --set image.repository=kubernetesui/dashboard \
  --set image.tag=v2.10.1  # 指定稳定版本，确保 ARM64 兼容

  #验证 Dashboard 部署状态
  # 查看 Dashboard 命名空间下的 Pod（ARM64 镜像会自动拉取，耐心等 1-3 分钟）
kubectl get pods -n kubernetes-dashboard -w

9. 访问 Dashboard

第一步：华为云安全组放行 8443 端口（否则无法访问）
默认华为云安全组会拦截外网端口，必须手动放行 8443（你端口转发用的端口）：
进入服务器详情页 → 找到「安全组」→ 点击安全组名称进入配置；
点击「入方向规则」→「添加规则」，按以下配置填写：
协议类型：TCP
端口范围：8443（和你端口转发的本地端口一致）
源地址：0.0.0.0/0（允许所有 IP 访问，测试用；生产环境可限制为你的本地 IP）
描述：Kubernetes Dashboard 访问
点击「确定」，安全组规则立即生效。

第二步：让端口转发在后台持续运行（避免终端关闭断开）
# 先停止之前的端口转发（如果还在运行）
sudo pkill -f "port-forward.*kubernetes-dashboard-kong-proxy"

# 后台运行端口转发（日志输出到 nohup.out，终端关闭不影响）
nohup kubectl -n kubernetes-dashboard port-forward svc/kubernetes-dashboard-kong-proxy 8443:443 > /tmp/dashboard-forward.log 2>&1 &

#验证是否运行成功：
ps -ef | grep port-forward | grep -v grep

第三步：本地浏览器访问 Dashboard
打开本地浏览器（Chrome/Firefox/Edge 均可），输入地址：
https://<你的服务器公网IP>:8443  # 例：https://123.45.67.89:8443

ps:这个时候会出现连接被拒绝的问题

#port-forward只监听了 127.0.0.1（默认行为）
ss -ltnp | grep 8443
#如果输出是
root@ecs-de54:~# ss -ltnp | grep 8443
LISTEN 0      4096       127.0.0.1:8443       0.0.0.0:*    users:(("kubectl",pid=31628,fd=8))       
LISTEN 0      4096           [::1]:8443          [::]:*    users:(("kubectl",pid=31628,fd=9))
#就说明port-forward 默认只监听 127.0.0.1（本机回环地址）所以：
#你在服务器里 curl -k https://localhost:8443 能通；
#但从公网（你的 Windows 电脑）连 183.87.33.92:8443 时，报文根本到不了 127.0.0.1，于是 TcpTestSucceeded : False。

10.公网访问Dashboard解决办法
把监听地址改成 0.0.0.0（或者只改成服务器内网地址也行）即可。
# 先停掉旧的转发
sudo pkill -f "port-forward.*kubernetes-dashboard-kong-proxy"

# 重新后台运行，显式指定 --address 0.0.0.0
nohup kubectl -n kubernetes-dashboard port-forward \
  --address 0.0.0.0 svc/kubernetes-dashboard-kong-proxy 8443:443 \
  > /tmp/dashboard-forward.log 2>&1 &

# 确认监听地址已变成 0.0.0.0
ss -ltnp | grep 8443

这个时候就可以在自己的本地电脑上面访问了
进入网站之后，它让我们输入令牌（令牌 (Token) 是 Kubernetes 的安全认证机制，就像你进入大楼的门禁卡，必须提供它才能访问 Dashboard 的管理界面。）

11.Kubernetes Dashboard 令牌登录指南

方法 1：使用你之前生成的 admin-token（推荐）
# 生成有效期为24小时的admin用户令牌（如果之前命令执行过，直接用之前输出的token）
kubectl -n kubernetes-dashboard create token admin-user

方法 2：如果之前命令未执行或令牌过期，重新创建
# 1. 创建admin服务账户（如果不存在）
kubectl create serviceaccount admin-user -n kubernetes-dashboard

# 2. 为admin账户绑定最高权限（cluster-admin角色）
kubectl create clusterrolebinding admin-user-binding \
  --clusterrole=cluster-admin \
  --serviceaccount=kubernetes-dashboard:admin-user

# 3. 生成并查看令牌
kubectl -n kubernetes-dashboard create token admin-user

终于完成了，这个单节点k8s部署真的麻烦，如果可以以后别叫我搭建k8s环境，我要吐了